{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79e28e5",
   "metadata": {},
   "source": [
    "# Weak instruments\n",
    "\n",
    "We've all heard that the rule of thumb for strong instruments is $F > 10$ (though troubling [recent work](https://arxiv.org/pdf/2010.05058.pdf) suggests that F might need to be much, much larger...). Let's explore in code the weak instruments problem, by examining the bias and precision of IV estimates in the just-identified case.\n",
    "\n",
    "First, we need to specify data-generating processes. The first stage is where we need to be careful. Remembering our goal, we need a data-generating process that is able to vary parameters that changes how weak the instrument is, AND how many instruments there are. Lets call $K$ the number of insturuments. We will change how weak the instruments are by varying the vector $\\pi$ in the equation:\n",
    "\n",
    "$$x_i = \\pi Z_i + v_i$$\n",
    "\n",
    "Intuitively, weak instruments will have $\\pi\\to 0$. For simplicity, let's assume (for now) $\\pi_k = \\pi\\: \\forall\\: k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae109053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats.distributions as iid\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dbcc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGP: y, x\n",
    "def dgp(N, beta, pi):\n",
    "    # we need values of X that are correlated with both Z and U\n",
    "    # generate values of X, u that are correlated\n",
    "    means_XUZ = [0, 5, 0]\n",
    "    covar_XUZ = [[2.0, 0.8, 0.5], \n",
    "                 [0.8, 0.5, 0],\n",
    "                 [0.5, 0, 1*(1/pi)]]\n",
    "    XUZ = scipy.stats.multivariate_normal(means_XUZ, covar_XUZ).rvs(size=N)\n",
    "    # create Y\n",
    "    X = \n",
    "    Y =  # use brackets to force output array to be (N,1) instead of (N,)\n",
    "    Z = \n",
    "    \n",
    "    return Y, X, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(1e3)\n",
    "true_beta = 2\n",
    "pi = 1\n",
    "Y, X, Z = dgp(N, true_beta, pi)\n",
    "Xi = np.c_[np.ones((N,1)), X]\n",
    "Zi = np.c_[np.ones((N,1)), Z]\n",
    "\n",
    "# test OLS regression\n",
    "print() # beta_1 biased!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa79cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test first stage\n",
    "print() # unbiased!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test IV\n",
    "print() # unbiased!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955d4a6",
   "metadata": {},
   "source": [
    "### Check your understanding\n",
    "1. I did not (explicitly) include an intercept in the DGP for Y, but I did in the regression and the resulting $\\hat{\\alpha}\\neq 0$. Why?\n",
    "2. How did I generate bias in the DGP? What is this bias a function of?\n",
    "3. How is relevance ($cov(X,Z)\\neq 0$ established? How did you know $E\\hat{\\pi} = 1$?\n",
    "4. What does each term in ``covar_XUZ`` represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e53c77e",
   "metadata": {},
   "source": [
    "## Iterating\n",
    "Now that we have our data-generating process, we can iterate over values of $\\pi$, and for **each value of $\\pi$** we want to:\n",
    "1. Draw a sample size of N L-times\n",
    "2. For each of these (L) draws, calculate the OLS and IV estimators.\n",
    "3. Plot a histogram of the (L) $\\hat{\\beta}_l^{iv}$ and $\\hat{\\beta}_l^{ols}$\n",
    "\n",
    "For good measure, let's also calculate the F statistic for each of our draws. Collecting this together in a function will help us stay organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d3a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(data):\n",
    "    '''\n",
    "    data: a tuple (Y, X, Z)\n",
    "    Given data, estimate OLS and IV, and the first-stage F statistic.\n",
    "    \n",
    "    Returns: a tuple (beta_ols, beta_iv, F_1ststage)\n",
    "    '''\n",
    "    Y, X, Z = data\n",
    "    # add intercepts\n",
    "    Xi = np.c_[np.ones((N,1)), X]\n",
    "    Zi = np.c_[np.ones((N,1)), Z]\n",
    "\n",
    "    # ols\n",
    "    beta_ols = np.linalg.solve(Xi.T@Xi, Xi.T@Y)\n",
    "    # iv\n",
    "    beta_iv = np.linalg.solve(Zi.T@Xi, Zi.T@Y)\n",
    "    \n",
    "    # F statistic\n",
    "    # 1. (total sum of squares)\n",
    "    pi_hat = np.linalg.solve(Zi.T@Zi, Zi.T@X)\n",
    "    xhat = \n",
    "    SSER = \n",
    "    # 2. need SSE (sum of squared errors)\n",
    "    SSEF = \n",
    "    # 3. calculate\n",
    "    F = ((SSER - SSEF)/SSEF)*(len(X)-2)\n",
    "    \n",
    "    return beta_ols, beta_iv, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the F statistic\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "Y, X, Z = dgp(N, true_beta, 0.2)\n",
    "Zi = np.c_[np.ones((N,1)), Z]\n",
    "print()\n",
    "OLS(X,Zi).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 100\n",
    "N = 1000\n",
    "true_beta = 2\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,7))\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for pi in [0.001, 0.01, 0.1, 0.2]:\n",
    "    results = [estimate(dgp(N, true_beta, pi)) for i in range(L)]\n",
    "    beta_ols = np.array([... for i in results]).squeeze()\n",
    "    beta_iv  = np.array([... for i in results]).squeeze()\n",
    "    meanF    = np.mean([... for i in results])\n",
    "        \n",
    "    ax[counter].hist(beta_ols, fill = 'red', alpha = 1, label = 'OLS')\n",
    "    ax[counter].hist(beta_iv,  fill = 'blue', alpha = 0.5, label = 'IV')\n",
    "    ax[counter].set_title(f\"pi = {pi}, F = {meanF:.2f}\")\n",
    "    \n",
    "    ax[counter].axvline(x=true_beta, color='black')\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "plt.legend(loc='upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
